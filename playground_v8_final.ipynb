{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c8ba5f-bb90-42de-9a96-ee78dfe661b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8171f9c-19e8-470a-8b5b-322dcb5b326b",
   "metadata": {},
   "source": [
    "# Part 0: The Checklist\n",
    "- [ ] Get the data\n",
    "- [ ] Do the One Class SVM, Isolation Tree, and Local Outlier Factor\n",
    "- [ ] Clip the Target\n",
    "- [ ] Arithmetic Mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6575816-a5b6-4b27-9f7e-e09e18b9c777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>O2_1</th>\n",
       "      <th>O2_2</th>\n",
       "      <th>O2_3</th>\n",
       "      <th>O2_4</th>\n",
       "      <th>O2_5</th>\n",
       "      <th>O2_6</th>\n",
       "      <th>O2_7</th>\n",
       "      <th>NH4_1</th>\n",
       "      <th>...</th>\n",
       "      <th>NO3_5</th>\n",
       "      <th>NO3_6</th>\n",
       "      <th>NO3_7</th>\n",
       "      <th>BOD5_1</th>\n",
       "      <th>BOD5_2</th>\n",
       "      <th>BOD5_3</th>\n",
       "      <th>BOD5_4</th>\n",
       "      <th>BOD5_5</th>\n",
       "      <th>BOD5_6</th>\n",
       "      <th>BOD5_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>7.500</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.545</td>\n",
       "      <td>9.265</td>\n",
       "      <td>8.110</td>\n",
       "      <td>8.430</td>\n",
       "      <td>7.150</td>\n",
       "      <td>0.180</td>\n",
       "      <td>...</td>\n",
       "      <td>4.950</td>\n",
       "      <td>1.730</td>\n",
       "      <td>1.800</td>\n",
       "      <td>4.800</td>\n",
       "      <td>3.150</td>\n",
       "      <td>10.665</td>\n",
       "      <td>10.465</td>\n",
       "      <td>16.645</td>\n",
       "      <td>5.750</td>\n",
       "      <td>10.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.10</td>\n",
       "      <td>13.533</td>\n",
       "      <td>40.900</td>\n",
       "      <td>8.770</td>\n",
       "      <td>9.265</td>\n",
       "      <td>6.015</td>\n",
       "      <td>10.070</td>\n",
       "      <td>7.150</td>\n",
       "      <td>1.107</td>\n",
       "      <td>...</td>\n",
       "      <td>20.050</td>\n",
       "      <td>9.530</td>\n",
       "      <td>7.695</td>\n",
       "      <td>4.550</td>\n",
       "      <td>6.950</td>\n",
       "      <td>2.040</td>\n",
       "      <td>5.200</td>\n",
       "      <td>5.725</td>\n",
       "      <td>2.950</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.21</td>\n",
       "      <td>3.710</td>\n",
       "      <td>5.420</td>\n",
       "      <td>8.770</td>\n",
       "      <td>9.265</td>\n",
       "      <td>4.550</td>\n",
       "      <td>10.070</td>\n",
       "      <td>7.150</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>4.580</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.960</td>\n",
       "      <td>4.935</td>\n",
       "      <td>4.950</td>\n",
       "      <td>4.725</td>\n",
       "      <td>6.075</td>\n",
       "      <td>6.750</td>\n",
       "      <td>3.500</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.39</td>\n",
       "      <td>8.700</td>\n",
       "      <td>8.100</td>\n",
       "      <td>9.500</td>\n",
       "      <td>9.200</td>\n",
       "      <td>5.200</td>\n",
       "      <td>8.670</td>\n",
       "      <td>6.670</td>\n",
       "      <td>0.280</td>\n",
       "      <td>...</td>\n",
       "      <td>8.450</td>\n",
       "      <td>2.070</td>\n",
       "      <td>1.730</td>\n",
       "      <td>6.300</td>\n",
       "      <td>4.700</td>\n",
       "      <td>3.500</td>\n",
       "      <td>6.200</td>\n",
       "      <td>8.670</td>\n",
       "      <td>2.900</td>\n",
       "      <td>7.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.07</td>\n",
       "      <td>8.050</td>\n",
       "      <td>8.650</td>\n",
       "      <td>7.960</td>\n",
       "      <td>9.265</td>\n",
       "      <td>3.290</td>\n",
       "      <td>10.070</td>\n",
       "      <td>7.150</td>\n",
       "      <td>0.360</td>\n",
       "      <td>...</td>\n",
       "      <td>2.020</td>\n",
       "      <td>1.730</td>\n",
       "      <td>0.760</td>\n",
       "      <td>4.800</td>\n",
       "      <td>4.970</td>\n",
       "      <td>3.950</td>\n",
       "      <td>2.800</td>\n",
       "      <td>8.400</td>\n",
       "      <td>3.500</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>3495</td>\n",
       "      <td>8.08</td>\n",
       "      <td>6.250</td>\n",
       "      <td>8.300</td>\n",
       "      <td>7.795</td>\n",
       "      <td>9.265</td>\n",
       "      <td>5.690</td>\n",
       "      <td>8.555</td>\n",
       "      <td>6.335</td>\n",
       "      <td>0.565</td>\n",
       "      <td>...</td>\n",
       "      <td>14.575</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.640</td>\n",
       "      <td>4.235</td>\n",
       "      <td>4.100</td>\n",
       "      <td>2.800</td>\n",
       "      <td>3.950</td>\n",
       "      <td>7.695</td>\n",
       "      <td>3.540</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>3496</td>\n",
       "      <td>8.09</td>\n",
       "      <td>6.630</td>\n",
       "      <td>6.630</td>\n",
       "      <td>8.370</td>\n",
       "      <td>7.600</td>\n",
       "      <td>0.636</td>\n",
       "      <td>8.430</td>\n",
       "      <td>7.150</td>\n",
       "      <td>1.300</td>\n",
       "      <td>...</td>\n",
       "      <td>4.580</td>\n",
       "      <td>1.730</td>\n",
       "      <td>1.800</td>\n",
       "      <td>4.900</td>\n",
       "      <td>3.150</td>\n",
       "      <td>2.040</td>\n",
       "      <td>6.075</td>\n",
       "      <td>8.415</td>\n",
       "      <td>2.155</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>3497</td>\n",
       "      <td>9.95</td>\n",
       "      <td>8.367</td>\n",
       "      <td>8.433</td>\n",
       "      <td>8.770</td>\n",
       "      <td>6.170</td>\n",
       "      <td>5.800</td>\n",
       "      <td>10.400</td>\n",
       "      <td>7.200</td>\n",
       "      <td>0.430</td>\n",
       "      <td>...</td>\n",
       "      <td>20.050</td>\n",
       "      <td>1.440</td>\n",
       "      <td>1.800</td>\n",
       "      <td>4.867</td>\n",
       "      <td>4.833</td>\n",
       "      <td>4.725</td>\n",
       "      <td>4.950</td>\n",
       "      <td>8.400</td>\n",
       "      <td>6.625</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>3498</td>\n",
       "      <td>9.52</td>\n",
       "      <td>10.000</td>\n",
       "      <td>6.630</td>\n",
       "      <td>9.545</td>\n",
       "      <td>9.265</td>\n",
       "      <td>3.290</td>\n",
       "      <td>8.980</td>\n",
       "      <td>2.310</td>\n",
       "      <td>0.300</td>\n",
       "      <td>...</td>\n",
       "      <td>20.050</td>\n",
       "      <td>9.530</td>\n",
       "      <td>7.695</td>\n",
       "      <td>10.700</td>\n",
       "      <td>5.400</td>\n",
       "      <td>4.725</td>\n",
       "      <td>3.300</td>\n",
       "      <td>6.750</td>\n",
       "      <td>6.625</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>3499</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.500</td>\n",
       "      <td>8.100</td>\n",
       "      <td>9.545</td>\n",
       "      <td>9.265</td>\n",
       "      <td>8.110</td>\n",
       "      <td>9.805</td>\n",
       "      <td>7.150</td>\n",
       "      <td>0.215</td>\n",
       "      <td>...</td>\n",
       "      <td>3.070</td>\n",
       "      <td>1.730</td>\n",
       "      <td>1.800</td>\n",
       "      <td>1.720</td>\n",
       "      <td>2.520</td>\n",
       "      <td>2.040</td>\n",
       "      <td>2.040</td>\n",
       "      <td>8.415</td>\n",
       "      <td>2.950</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target    O2_1    O2_2   O2_3   O2_4   O2_5    O2_6   O2_7  NH4_1  \\\n",
       "0        0    8.59   7.500   9.000  9.545  9.265  8.110   8.430  7.150  0.180   \n",
       "1        1    9.10  13.533  40.900  8.770  9.265  6.015  10.070  7.150  1.107   \n",
       "2        2    8.21   3.710   5.420  8.770  9.265  4.550  10.070  7.150  0.020   \n",
       "3        3    8.39   8.700   8.100  9.500  9.200  5.200   8.670  6.670  0.280   \n",
       "4        4    8.07   8.050   8.650  7.960  9.265  3.290  10.070  7.150  0.360   \n",
       "...    ...     ...     ...     ...    ...    ...    ...     ...    ...    ...   \n",
       "3495  3495    8.08   6.250   8.300  7.795  9.265  5.690   8.555  6.335  0.565   \n",
       "3496  3496    8.09   6.630   6.630  8.370  7.600  0.636   8.430  7.150  1.300   \n",
       "3497  3497    9.95   8.367   8.433  8.770  6.170  5.800  10.400  7.200  0.430   \n",
       "3498  3498    9.52  10.000   6.630  9.545  9.265  3.290   8.980  2.310  0.300   \n",
       "3499  3499    8.51   8.500   8.100  9.545  9.265  8.110   9.805  7.150  0.215   \n",
       "\n",
       "      ...   NO3_5  NO3_6  NO3_7  BOD5_1  BOD5_2  BOD5_3  BOD5_4  BOD5_5  \\\n",
       "0     ...   4.950  1.730  1.800   4.800   3.150  10.665  10.465  16.645   \n",
       "1     ...  20.050  9.530  7.695   4.550   6.950   2.040   5.200   5.725   \n",
       "2     ...   4.580  3.025  3.960   4.935   4.950   4.725   6.075   6.750   \n",
       "3     ...   8.450  2.070  1.730   6.300   4.700   3.500   6.200   8.670   \n",
       "4     ...   2.020  1.730  0.760   4.800   4.970   3.950   2.800   8.400   \n",
       "...   ...     ...    ...    ...     ...     ...     ...     ...     ...   \n",
       "3495  ...  14.575  0.636  1.640   4.235   4.100   2.800   3.950   7.695   \n",
       "3496  ...   4.580  1.730  1.800   4.900   3.150   2.040   6.075   8.415   \n",
       "3497  ...  20.050  1.440  1.800   4.867   4.833   4.725   4.950   8.400   \n",
       "3498  ...  20.050  9.530  7.695  10.700   5.400   4.725   3.300   6.750   \n",
       "3499  ...   3.070  1.730  1.800   1.720   2.520   2.040   2.040   8.415   \n",
       "\n",
       "      BOD5_6  BOD5_7  \n",
       "0      5.750   10.37  \n",
       "1      2.950    2.23  \n",
       "2      3.500    3.17  \n",
       "3      2.900    7.37  \n",
       "4      3.500    3.90  \n",
       "...      ...     ...  \n",
       "3495   3.540    2.50  \n",
       "3496   2.155    2.90  \n",
       "3497   6.625    4.20  \n",
       "3498   6.625    5.00  \n",
       "3499   2.950    2.27  \n",
       "\n",
       "[3500 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sample_submission.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7413de32-0e82-4ea9-9153-9cea111a962d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mSGDOneClassSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'optimal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meta0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpower_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Solves linear One-Class SVM using Stochastic Gradient Descent.\n",
       "\n",
       "This implementation is meant to be used with a kernel approximation\n",
       "technique (e.g. `sklearn.kernel_approximation.Nystroem`) to obtain results\n",
       "similar to `sklearn.svm.OneClassSVM` which uses a Gaussian kernel by\n",
       "default.\n",
       "\n",
       "Read more in the :ref:`User Guide <sgd_online_one_class_svm>`.\n",
       "\n",
       ".. versionadded:: 1.0\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "nu : float, default=0.5\n",
       "    The nu parameter of the One Class SVM: an upper bound on the\n",
       "    fraction of training errors and a lower bound of the fraction of\n",
       "    support vectors. Should be in the interval (0, 1]. By default 0.5\n",
       "    will be taken.\n",
       "\n",
       "fit_intercept : bool, default=True\n",
       "    Whether the intercept should be estimated or not. Defaults to True.\n",
       "\n",
       "max_iter : int, default=1000\n",
       "    The maximum number of passes over the training data (aka epochs).\n",
       "    It only impacts the behavior in the ``fit`` method, and not the\n",
       "    `partial_fit`. Defaults to 1000.\n",
       "\n",
       "tol : float or None, default=1e-3\n",
       "    The stopping criterion. If it is not None, the iterations will stop\n",
       "    when (loss > previous_loss - tol). Defaults to 1e-3.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Whether or not the training data should be shuffled after each epoch.\n",
       "    Defaults to True.\n",
       "\n",
       "verbose : int, default=0\n",
       "    The verbosity level.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    The seed of the pseudo random number generator to use when shuffling\n",
       "    the data.  If int, random_state is the seed used by the random number\n",
       "    generator; If RandomState instance, random_state is the random number\n",
       "    generator; If None, the random number generator is the RandomState\n",
       "    instance used by `np.random`.\n",
       "\n",
       "learning_rate : {'constant', 'optimal', 'invscaling', 'adaptive'}, default='optimal'\n",
       "    The learning rate schedule to use with `fit`. (If using `partial_fit`,\n",
       "    learning rate must be controlled directly).\n",
       "\n",
       "    - 'constant': `eta = eta0`\n",
       "    - 'optimal': `eta = 1.0 / (alpha * (t + t0))`\n",
       "      where t0 is chosen by a heuristic proposed by Leon Bottou.\n",
       "    - 'invscaling': `eta = eta0 / pow(t, power_t)`\n",
       "    - 'adaptive': eta = eta0, as long as the training keeps decreasing.\n",
       "      Each time n_iter_no_change consecutive epochs fail to decrease the\n",
       "      training loss by tol or fail to increase validation score by tol if\n",
       "      early_stopping is True, the current learning rate is divided by 5.\n",
       "\n",
       "eta0 : float, default=0.0\n",
       "    The initial learning rate for the 'constant', 'invscaling' or\n",
       "    'adaptive' schedules. The default value is 0.0 as eta0 is not used by\n",
       "    the default schedule 'optimal'.\n",
       "\n",
       "power_t : float, default=0.5\n",
       "    The exponent for inverse scaling learning rate [default 0.5].\n",
       "\n",
       "warm_start : bool, default=False\n",
       "    When set to True, reuse the solution of the previous call to fit as\n",
       "    initialization, otherwise, just erase the previous solution.\n",
       "    See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "    Repeatedly calling fit or partial_fit when warm_start is True can\n",
       "    result in a different solution than when calling fit a single time\n",
       "    because of the way the data is shuffled.\n",
       "    If a dynamic learning rate is used, the learning rate is adapted\n",
       "    depending on the number of samples already seen. Calling ``fit`` resets\n",
       "    this counter, while ``partial_fit``  will result in increasing the\n",
       "    existing counter.\n",
       "\n",
       "average : bool or int, default=False\n",
       "    When set to True, computes the averaged SGD weights and stores the\n",
       "    result in the ``coef_`` attribute. If set to an int greater than 1,\n",
       "    averaging will begin once the total number of samples seen reaches\n",
       "    average. So ``average=10`` will begin averaging after seeing 10\n",
       "    samples.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : ndarray of shape (1, n_features)\n",
       "    Weights assigned to the features.\n",
       "\n",
       "offset_ : ndarray of shape (1,)\n",
       "    Offset used to define the decision function from the raw scores.\n",
       "    We have the relation: decision_function = score_samples - offset.\n",
       "\n",
       "n_iter_ : int\n",
       "    The actual number of iterations to reach the stopping criterion.\n",
       "\n",
       "t_ : int\n",
       "    Number of weight updates performed during training.\n",
       "    Same as ``(n_iter_ * n_samples + 1)``.\n",
       "\n",
       "loss_function_ : concrete ``LossFunction``\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "sklearn.svm.OneClassSVM : Unsupervised Outlier Detection.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "This estimator has a linear complexity in the number of training samples\n",
       "and is thus better suited than the `sklearn.svm.OneClassSVM`\n",
       "implementation for datasets with a large number of training samples (say\n",
       "> 10,000).\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn import linear_model\n",
       ">>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
       ">>> clf = linear_model.SGDOneClassSVM(random_state=42)\n",
       ">>> clf.fit(X)\n",
       "SGDOneClassSVM(random_state=42)\n",
       "\n",
       ">>> print(clf.predict([[4, 4]]))\n",
       "[1]\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SGDOneClassSVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f540848-4b61-40f3-81a3-57f8c7ea80e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocs = SGDOneClassSVM(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed9b7a8e-3567-482d-9ed3-cea94180a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55971ce6-4d57-4e5a-897c-92b014f34707",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocs.fit(X)\n",
    "ocs_pred = ocs.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d98ca44e-9709-40d9-8176-556c31d65687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(ocs_pred==-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c35161c2-f485-44ab-a4f4-d78d2a27a7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  4,  5,  7,  8,  9, 10, 11, 14, 15])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(ocs_pred==-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "792c1d8f-51f5-4de6-8794-9b22413ac059",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocs_n = SGDOneClassSVM(0.5)\n",
    "ocs_n.fit(df)\n",
    "ocs_n_pred = ocs_n.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cb5bf9d-9cfa-4a72-be54-f880a9bb0b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 14, 15])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(ocs_n_pred==-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eca59eb1-bf3a-4dea-ad06-d5ff12442630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(ocs_n_pred==-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "207216eb-dfc2-4a41-ac01-be05eb48728d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, ...,  1,  1,  1], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocs_n_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d70e709a-83ae-4e9e-ac23-391e02167813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  76,  133,  282,  463,  476,  510,  613,  797, 1054, 1375, 1502,\n",
       "       2006, 2533, 2535, 2627, 2793, 3464])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocs_id = SGDOneClassSVM(0.3)\n",
    "ocs_id.fit(df.drop('id', axis=1))\n",
    "ocs_id_pred = ocs_id.predict(df.drop('id', axis=1))\n",
    "np.where(ocs_id_pred==-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c182a23-9cf5-40a9-8156-76830f5c9220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
